//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31833905
// Cuda compilation tools, release 11.8, V11.8.89
// Based on NVVM 7.0.1
//

.version 7.8
.target sm_52
.address_size 64

	// .globl	__raygen__psdr_rg
.visible .const .align 8 .b8 params[160];

.visible .entry __raygen__psdr_rg()
{
	.local .align 4 .b8 	__local_depot0[24];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<14>;
	.reg .f32 	%f<35>;
	.reg .b32 	%r<64>;
	.reg .b64 	%rd<91>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd11, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	// begin inline asm
	call (%r23), _optix_get_launch_index_x, ();
	// end inline asm
	shr.u64 	%rd12, %rd11, 32;
	cvt.u32.u64 	%r58, %rd12;
	cvt.u32.u64 	%r57, %rd11;
	ld.const.u64 	%rd13, [params];
	cvta.to.global.u64 	%rd14, %rd13;
	cvt.s64.s32 	%rd1, %r23;
	mul.wide.s32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.f32 	%f6, [%rd16];
	st.local.f32 	[%rd2], %f6;
	ld.const.u64 	%rd17, [params+8];
	cvta.to.global.u64 	%rd18, %rd17;
	add.s64 	%rd19, %rd18, %rd15;
	ld.global.f32 	%f7, [%rd19];
	st.local.f32 	[%rd2+4], %f7;
	ld.const.u64 	%rd20, [params+16];
	cvta.to.global.u64 	%rd21, %rd20;
	add.s64 	%rd22, %rd21, %rd15;
	ld.global.f32 	%f8, [%rd22];
	st.local.f32 	[%rd2+8], %f8;
	ld.const.u64 	%rd23, [params+48];
	cvta.to.global.u64 	%rd24, %rd23;
	add.s64 	%rd25, %rd24, %rd15;
	ld.global.f32 	%f33, [%rd25];
	st.local.f32 	[%rd2+12], %f33;
	mov.u32 	%r26, 0;
	st.local.u32 	[%rd2+16], %r26;
	mov.u32 	%r56, 1;
	st.local.u32 	[%rd2+20], %r56;
	ld.const.u32 	%r3, [params+128];
	setp.eq.s32 	%p1, %r3, 0;
	@%p1 bra 	$L__BB0_10;

	ld.const.u32 	%r4, [params+132];
	ld.const.u64 	%rd3, [params+152];
	ld.const.u64 	%rd26, [params+24];
	cvta.to.global.u64 	%rd27, %rd26;
	shl.b64 	%rd28, %rd1, 2;
	add.s64 	%rd4, %rd27, %rd28;
	ld.const.u64 	%rd29, [params+32];
	cvta.to.global.u64 	%rd30, %rd29;
	add.s64 	%rd5, %rd30, %rd28;
	ld.const.u64 	%rd31, [params+40];
	cvta.to.global.u64 	%rd32, %rd31;
	add.s64 	%rd6, %rd32, %rd28;

$L__BB0_2:
	ld.local.u32 	%r59, [%rd2+16];
	setp.ge.s32 	%p2, %r59, %r4;
	setp.eq.s32 	%p3, %r56, -2;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_5;

	ld.local.f32 	%f9, [%rd2];
	ld.local.f32 	%f10, [%rd2+4];
	ld.local.f32 	%f11, [%rd2+8];
	ld.global.f32 	%f12, [%rd4];
	ld.global.f32 	%f13, [%rd5];
	ld.global.f32 	%f14, [%rd6];
	mov.f32 	%f15, 0f3A83126F;
	mov.f32 	%f17, 0f00000000;
	mov.u32 	%r34, 1;
	mov.u32 	%r35, 0;
	// begin inline asm
	call (%r58, %r57), _optix_trace_2, (%rd3, %f9, %f10, %f11, %f12, %f13, %f14, %f15, %f33, %f17, %r34, %r34, %r35, %r34, %r35, %r58, %r57);
	// end inline asm
	ld.local.f32 	%f33, [%rd2+12];
	setp.geu.f32 	%p5, %f33, 0f00000000;
	ld.local.u32 	%r56, [%rd2+20];
	setp.ne.s32 	%p6, %r56, -2;
	and.pred  	%p7, %p5, %p6;
	@%p7 bra 	$L__BB0_2;

	ld.local.u32 	%r59, [%rd2+16];

$L__BB0_5:
	setp.gt.s32 	%p8, %r59, 0;
	@%p8 bra 	$L__BB0_7;
	bra.uni 	$L__BB0_6;

$L__BB0_7:
	cvt.u32.u64 	%r41, %rd1;
	mul.lo.s32 	%r60, %r4, %r41;
	setp.ne.s32 	%p9, %r3, 1;
	@%p9 bra 	$L__BB0_9;

	ld.const.u64 	%rd50, [params+136];
	cvta.to.global.u64 	%rd51, %rd50;
	add.s64 	%rd53, %rd51, %rd28;
	cvt.rn.f32.s32 	%f18, %r59;
	ld.global.f32 	%f19, [%rd53];
	mul.f32 	%f20, %f19, %f18;
	cvt.rmi.f32.f32 	%f21, %f20;
	cvt.rzi.u32.f32 	%r42, %f21;
	add.s32 	%r60, %r60, %r42;

$L__BB0_9:
	ld.const.u64 	%rd54, [params+88];
	cvta.to.global.u64 	%rd55, %rd54;
	mul.wide.u32 	%rd56, %r60, 4;
	add.s64 	%rd57, %rd55, %rd56;
	ld.global.u32 	%r43, [%rd57];
	ld.const.u64 	%rd58, [params+56];
	cvta.to.global.u64 	%rd59, %rd58;
	add.s64 	%rd61, %rd59, %rd28;
	st.global.u32 	[%rd61], %r43;
	ld.const.u64 	%rd62, [params+96];
	cvta.to.global.u64 	%rd63, %rd62;
	add.s64 	%rd64, %rd63, %rd56;
	ld.global.u32 	%r44, [%rd64];
	ld.const.u64 	%rd65, [params+64];
	cvta.to.global.u64 	%rd66, %rd65;
	add.s64 	%rd67, %rd66, %rd28;
	st.global.u32 	[%rd67], %r44;
	ld.const.u64 	%rd68, [params+104];
	cvta.to.global.u64 	%rd69, %rd68;
	add.s64 	%rd70, %rd69, %rd56;
	ld.global.f32 	%f22, [%rd70];
	ld.const.u64 	%rd71, [params+72];
	cvta.to.global.u64 	%rd72, %rd71;
	add.s64 	%rd73, %rd72, %rd28;
	st.global.f32 	[%rd73], %f22;
	ld.const.u64 	%rd74, [params+112];
	cvta.to.global.u64 	%rd75, %rd74;
	add.s64 	%rd76, %rd75, %rd56;
	ld.global.f32 	%f23, [%rd76];
	ld.const.u64 	%rd77, [params+80];
	cvta.to.global.u64 	%rd78, %rd77;
	add.s64 	%rd79, %rd78, %rd28;
	st.global.f32 	[%rd79], %f23;
	ld.const.u64 	%rd80, [params+120];
	cvta.to.global.u64 	%rd81, %rd80;
	add.s64 	%rd82, %rd81, %rd28;
	st.global.u32 	[%rd82], %r59;
	bra.uni 	$L__BB0_13;

$L__BB0_10:
	ld.const.u64 	%rd7, [params+152];
	ld.const.u64 	%rd83, [params+24];
	cvta.to.global.u64 	%rd84, %rd83;
	shl.b64 	%rd85, %rd1, 2;
	add.s64 	%rd8, %rd84, %rd85;
	ld.const.u64 	%rd86, [params+32];
	cvta.to.global.u64 	%rd87, %rd86;
	add.s64 	%rd9, %rd87, %rd85;
	ld.const.u64 	%rd88, [params+40];
	cvta.to.global.u64 	%rd89, %rd88;
	add.s64 	%rd10, %rd89, %rd85;
	mov.u32 	%r61, 1;

$L__BB0_11:
	add.s32 	%r46, %r61, 1;
	setp.lt.u32 	%p10, %r46, 2;
	@%p10 bra 	$L__BB0_13;

	ld.local.f32 	%f24, [%rd2];
	ld.local.f32 	%f25, [%rd2+4];
	ld.local.f32 	%f26, [%rd2+8];
	ld.global.f32 	%f27, [%rd8];
	ld.global.f32 	%f28, [%rd9];
	ld.global.f32 	%f29, [%rd10];
	mov.f32 	%f30, 0f3A83126F;
	mov.f32 	%f32, 0f00000000;
	mov.u32 	%r52, 1;
	mov.u32 	%r53, 0;
	// begin inline asm
	call (%r58, %r57), _optix_trace_2, (%rd7, %f24, %f25, %f26, %f27, %f28, %f29, %f30, %f33, %f32, %r52, %r52, %r53, %r52, %r53, %r58, %r57);
	// end inline asm
	ld.local.f32 	%f33, [%rd2+12];
	setp.geu.f32 	%p11, %f33, 0f00000000;
	ld.local.u32 	%r61, [%rd2+20];
	setp.ne.s32 	%p12, %r61, -2;
	and.pred  	%p13, %p11, %p12;
	@%p13 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_13;

$L__BB0_6:
	ld.const.u64 	%rd34, [params+56];
	cvta.to.global.u64 	%rd35, %rd34;
	add.s64 	%rd37, %rd35, %rd28;
	mov.u32 	%r38, -1;
	st.global.u32 	[%rd37], %r38;
	ld.const.u64 	%rd38, [params+64];
	cvta.to.global.u64 	%rd39, %rd38;
	add.s64 	%rd40, %rd39, %rd28;
	st.global.u32 	[%rd40], %r38;
	ld.const.u64 	%rd41, [params+72];
	cvta.to.global.u64 	%rd42, %rd41;
	add.s64 	%rd43, %rd42, %rd28;
	mov.u32 	%r39, -1082130432;
	st.global.u32 	[%rd43], %r39;
	ld.const.u64 	%rd44, [params+80];
	cvta.to.global.u64 	%rd45, %rd44;
	add.s64 	%rd46, %rd45, %rd28;
	st.global.u32 	[%rd46], %r39;
	ld.const.u64 	%rd47, [params+120];
	cvta.to.global.u64 	%rd48, %rd47;
	add.s64 	%rd49, %rd48, %rd28;
	mov.u32 	%r40, 0;
	st.global.u32 	[%rd49], %r40;

$L__BB0_13:
	ret;

}
	// .globl	__miss__psdr_ms
.visible .entry __miss__psdr_ms()
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<54>;
	.reg .b64 	%rd<53>;


	// begin inline asm
	call (%r21), _optix_get_launch_index_x, ();
	// end inline asm
	ld.const.u64 	%rd6, [params+56];
	cvta.to.global.u64 	%rd7, %rd6;
	mul.wide.u32 	%rd8, %r21, 4;
	add.s64 	%rd9, %rd7, %rd8;
	mov.u32 	%r24, -1;
	st.global.u32 	[%rd9], %r24;
	ld.const.u64 	%rd10, [params+64];
	cvta.to.global.u64 	%rd11, %rd10;
	add.s64 	%rd12, %rd11, %rd8;
	st.global.u32 	[%rd12], %r24;
	ld.const.u64 	%rd13, [params+72];
	cvta.to.global.u64 	%rd14, %rd13;
	add.s64 	%rd15, %rd14, %rd8;
	mov.u32 	%r25, -1082130432;
	st.global.u32 	[%rd15], %r25;
	ld.const.u64 	%rd16, [params+80];
	cvta.to.global.u64 	%rd17, %rd16;
	add.s64 	%rd18, %rd17, %rd8;
	st.global.u32 	[%rd18], %r25;
	ld.const.u32 	%r2, [params+128];
	setp.eq.s32 	%p1, %r2, 0;
	@%p1 bra 	$L__BB1_10;

	setp.lt.s32 	%p2, %r2, 1;
	@%p2 bra 	$L__BB1_11;

	// begin inline asm
	call (%r26), _optix_get_payload_0, ();
	// end inline asm
	// begin inline asm
	call (%r27), _optix_get_payload_1, ();
	// end inline asm
	cvt.u64.u32 	%rd19, %r26;
	cvt.u64.u32 	%rd20, %r27;
	bfi.b64 	%rd1, %rd19, %rd20, 32, 32;
	ld.const.u32 	%r3, [params+132];
	mul.lo.s32 	%r4, %r3, %r21;
	ld.u32 	%r5, [%rd1+16];
	setp.ge.s32 	%p3, %r5, %r3;
	@%p3 bra 	$L__BB1_9;

	ld.const.u64 	%rd21, [params+88];
	cvta.to.global.u64 	%rd2, %rd21;
	ld.const.u64 	%rd22, [params+96];
	cvta.to.global.u64 	%rd3, %rd22;
	ld.const.u64 	%rd23, [params+104];
	cvta.to.global.u64 	%rd4, %rd23;
	ld.const.u64 	%rd24, [params+112];
	cvta.to.global.u64 	%rd5, %rd24;
	add.s32 	%r28, %r5, 1;
	max.s32 	%r6, %r3, %r28;
	sub.s32 	%r29, %r6, %r5;
	and.b32  	%r50, %r29, 3;
	setp.eq.s32 	%p4, %r50, 0;
	mov.u32 	%r51, %r5;
	@%p4 bra 	$L__BB1_6;

	add.s32 	%r48, %r5, %r4;
	mov.u32 	%r51, %r5;

$L__BB1_5:
	.pragma "nounroll";
	mul.wide.u32 	%rd25, %r48, 4;
	add.s64 	%rd26, %rd2, %rd25;
	mov.u32 	%r30, -1;
	st.global.u32 	[%rd26], %r30;
	add.s64 	%rd27, %rd3, %rd25;
	st.global.u32 	[%rd27], %r30;
	add.s64 	%rd28, %rd4, %rd25;
	mov.u32 	%r31, -1082130432;
	st.global.u32 	[%rd28], %r31;
	add.s64 	%rd29, %rd5, %rd25;
	st.global.u32 	[%rd29], %r31;
	add.s32 	%r51, %r51, 1;
	add.s32 	%r48, %r48, 1;
	add.s32 	%r50, %r50, -1;
	setp.ne.s32 	%p5, %r50, 0;
	@%p5 bra 	$L__BB1_5;

$L__BB1_6:
	not.b32 	%r32, %r5;
	add.s32 	%r33, %r6, %r32;
	setp.lt.u32 	%p6, %r33, 3;
	@%p6 bra 	$L__BB1_9;

	add.s32 	%r34, %r51, %r4;
	add.s32 	%r52, %r34, 3;

$L__BB1_8:
	add.s32 	%r35, %r4, %r51;
	mul.wide.u32 	%rd30, %r35, 4;
	add.s64 	%rd31, %rd2, %rd30;
	mov.u32 	%r36, -1;
	st.global.u32 	[%rd31], %r36;
	add.s64 	%rd32, %rd3, %rd30;
	st.global.u32 	[%rd32], %r36;
	add.s64 	%rd33, %rd4, %rd30;
	mov.u32 	%r37, -1082130432;
	st.global.u32 	[%rd33], %r37;
	add.s64 	%rd34, %rd5, %rd30;
	st.global.u32 	[%rd34], %r37;
	add.s32 	%r38, %r52, -2;
	mul.wide.u32 	%rd35, %r38, 4;
	add.s64 	%rd36, %rd2, %rd35;
	st.global.u32 	[%rd36], %r36;
	add.s64 	%rd37, %rd3, %rd35;
	st.global.u32 	[%rd37], %r36;
	add.s64 	%rd38, %rd4, %rd35;
	st.global.u32 	[%rd38], %r37;
	add.s64 	%rd39, %rd5, %rd35;
	st.global.u32 	[%rd39], %r37;
	add.s32 	%r39, %r52, -1;
	mul.wide.u32 	%rd40, %r39, 4;
	add.s64 	%rd41, %rd2, %rd40;
	st.global.u32 	[%rd41], %r36;
	add.s64 	%rd42, %rd3, %rd40;
	st.global.u32 	[%rd42], %r36;
	add.s64 	%rd43, %rd4, %rd40;
	st.global.u32 	[%rd43], %r37;
	add.s64 	%rd44, %rd5, %rd40;
	st.global.u32 	[%rd44], %r37;
	mul.wide.u32 	%rd45, %r52, 4;
	add.s64 	%rd46, %rd2, %rd45;
	st.global.u32 	[%rd46], %r36;
	add.s64 	%rd47, %rd3, %rd45;
	st.global.u32 	[%rd47], %r36;
	add.s64 	%rd48, %rd4, %rd45;
	st.global.u32 	[%rd48], %r37;
	add.s64 	%rd49, %rd5, %rd45;
	st.global.u32 	[%rd49], %r37;
	add.s32 	%r52, %r52, 4;
	add.s32 	%r51, %r51, 4;
	setp.lt.s32 	%p7, %r51, %r3;
	@%p7 bra 	$L__BB1_8;

$L__BB1_9:
	mov.u32 	%r40, 0;
	st.u32 	[%rd1], %r40;
	st.u32 	[%rd1+4], %r40;
	st.u32 	[%rd1+8], %r40;
	mov.u32 	%r41, -1082130432;
	st.u32 	[%rd1+12], %r41;
	mov.u32 	%r42, -2;
	st.u32 	[%rd1+20], %r42;
	bra.uni 	$L__BB1_11;

$L__BB1_10:
	// begin inline asm
	call (%r43), _optix_get_payload_0, ();
	// end inline asm
	// begin inline asm
	call (%r44), _optix_get_payload_1, ();
	// end inline asm
	cvt.u64.u32 	%rd50, %r43;
	cvt.u64.u32 	%rd51, %r44;
	bfi.b64 	%rd52, %rd50, %rd51, 32, 32;
	mov.u32 	%r45, 0;
	st.u32 	[%rd52], %r45;
	st.u32 	[%rd52+4], %r45;
	st.u32 	[%rd52+8], %r45;
	st.u32 	[%rd52+12], %r25;
	mov.u32 	%r47, -2;
	st.u32 	[%rd52+20], %r47;

$L__BB1_11:
	ret;

}
	// .globl	__closesthit__psdr_ch
.visible .entry __closesthit__psdr_ch()
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<38>;
	.reg .b32 	%r<37>;
	.reg .b64 	%rd<55>;


	// begin inline asm
	call (%r4), _optix_get_payload_0, ();
	// end inline asm
	// begin inline asm
	call (%r5), _optix_get_payload_1, ();
	// end inline asm
	cvt.u64.u32 	%rd4, %r4;
	cvt.u64.u32 	%rd5, %r5;
	bfi.b64 	%rd1, %rd4, %rd5, 32, 32;
	// begin inline asm
	call (%rd3), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	// begin inline asm
	call (%r6), _optix_read_primitive_idx, ();
	// end inline asm
	// begin inline asm
	call (%r7), _optix_get_launch_index_x, ();
	// end inline asm
	mul.lo.s32 	%r10, %r6, 3;
	ld.u64 	%rd6, [%rd3+16];
	mul.wide.s32 	%rd7, %r10, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.u32 	%r11, [%rd8];
	mul.lo.s32 	%r12, %r11, 3;
	ld.u64 	%rd9, [%rd3+8];
	mul.wide.s32 	%rd10, %r12, 4;
	add.s64 	%rd11, %rd9, %rd10;
	ld.f32 	%f5, [%rd11];
	ld.f32 	%f6, [%rd11+4];
	ld.f32 	%f7, [%rd11+8];
	ld.u32 	%r13, [%rd8+4];
	mul.lo.s32 	%r14, %r13, 3;
	mul.wide.s32 	%rd12, %r14, 4;
	add.s64 	%rd13, %rd9, %rd12;
	ld.f32 	%f8, [%rd13];
	ld.f32 	%f9, [%rd13+4];
	ld.f32 	%f10, [%rd13+8];
	ld.u32 	%r15, [%rd8+8];
	mul.lo.s32 	%r16, %r15, 3;
	mul.wide.s32 	%rd14, %r16, 4;
	add.s64 	%rd15, %rd9, %rd14;
	ld.f32 	%f11, [%rd15];
	ld.f32 	%f12, [%rd15+4];
	ld.f32 	%f13, [%rd15+8];
	// begin inline asm
	call (%f3, %f4), _optix_get_triangle_barycentrics, ();
	// end inline asm
	mov.f32 	%f14, 0f3F800000;
	sub.f32 	%f15, %f14, %f3;
	sub.f32 	%f16, %f15, %f4;
	mul.f32 	%f17, %f5, %f16;
	fma.rn.f32 	%f18, %f8, %f3, %f17;
	fma.rn.f32 	%f19, %f11, %f4, %f18;
	mul.f32 	%f20, %f6, %f16;
	fma.rn.f32 	%f21, %f9, %f3, %f20;
	fma.rn.f32 	%f22, %f12, %f4, %f21;
	mul.f32 	%f23, %f7, %f16;
	fma.rn.f32 	%f24, %f10, %f3, %f23;
	fma.rn.f32 	%f25, %f13, %f4, %f24;
	ld.f32 	%f26, [%rd1];
	sub.f32 	%f27, %f19, %f26;
	ld.f32 	%f28, [%rd1+4];
	sub.f32 	%f29, %f22, %f28;
	ld.f32 	%f30, [%rd1+8];
	sub.f32 	%f31, %f25, %f30;
	st.f32 	[%rd1], %f19;
	st.f32 	[%rd1+4], %f22;
	st.f32 	[%rd1+8], %f25;
	mul.f32 	%f32, %f29, %f29;
	fma.rn.f32 	%f33, %f27, %f27, %f32;
	fma.rn.f32 	%f34, %f31, %f31, %f33;
	sqrt.rn.f32 	%f35, %f34;
	ld.f32 	%f36, [%rd1+12];
	sub.f32 	%f37, %f36, %f35;
	st.f32 	[%rd1+12], %f37;
	ld.u32 	%r17, [%rd3+24];
	st.u32 	[%rd1+20], %r17;
	setp.lt.s32 	%p1, %r17, 1;
	ld.const.u32 	%r3, [params+128];
	@%p1 bra 	$L__BB2_3;

	setp.ne.s32 	%p2, %r3, 2;
	@%p2 bra 	$L__BB2_7;

	ld.const.u32 	%r18, [params+132];
	ld.u32 	%r19, [%rd1+16];
	mad.lo.s32 	%r20, %r18, %r7, %r19;
	ld.u32 	%r21, [%rd3];
	add.s32 	%r22, %r21, %r6;
	ld.const.u64 	%rd16, [params+88];
	cvta.to.global.u64 	%rd17, %rd16;
	mul.wide.u32 	%rd18, %r20, 4;
	add.s64 	%rd19, %rd17, %rd18;
	st.global.u32 	[%rd19], %r22;
	ld.u32 	%r23, [%rd3+4];
	ld.const.u64 	%rd20, [params+96];
	cvta.to.global.u64 	%rd21, %rd20;
	add.s64 	%rd22, %rd21, %rd18;
	st.global.u32 	[%rd22], %r23;
	ld.const.u64 	%rd23, [params+104];
	cvta.to.global.u64 	%rd24, %rd23;
	add.s64 	%rd25, %rd24, %rd18;
	st.global.f32 	[%rd25], %f3;
	ld.const.u64 	%rd26, [params+112];
	cvta.to.global.u64 	%rd27, %rd26;
	add.s64 	%rd28, %rd27, %rd18;
	st.global.f32 	[%rd28], %f4;
	ld.u32 	%r24, [%rd1+16];
	add.s32 	%r25, %r24, 1;
	st.u32 	[%rd1+16], %r25;
	bra.uni 	$L__BB2_7;

$L__BB2_3:
	setp.eq.s32 	%p3, %r3, 0;
	@%p3 bra 	$L__BB2_6;

	setp.ne.s32 	%p4, %r3, 1;
	@%p4 bra 	$L__BB2_7;

	ld.const.u32 	%r26, [params+132];
	ld.u32 	%r27, [%rd1+16];
	mad.lo.s32 	%r28, %r26, %r7, %r27;
	ld.u32 	%r29, [%rd3];
	add.s32 	%r30, %r29, %r6;
	ld.const.u64 	%rd29, [params+88];
	cvta.to.global.u64 	%rd30, %rd29;
	mul.wide.u32 	%rd31, %r28, 4;
	add.s64 	%rd32, %rd30, %rd31;
	st.global.u32 	[%rd32], %r30;
	ld.u32 	%r31, [%rd3+4];
	ld.const.u64 	%rd33, [params+96];
	cvta.to.global.u64 	%rd34, %rd33;
	add.s64 	%rd35, %rd34, %rd31;
	st.global.u32 	[%rd35], %r31;
	ld.const.u64 	%rd36, [params+104];
	cvta.to.global.u64 	%rd37, %rd36;
	add.s64 	%rd38, %rd37, %rd31;
	st.global.f32 	[%rd38], %f3;
	ld.const.u64 	%rd39, [params+112];
	cvta.to.global.u64 	%rd40, %rd39;
	add.s64 	%rd41, %rd40, %rd31;
	st.global.f32 	[%rd41], %f4;
	ld.u32 	%r32, [%rd1+16];
	add.s32 	%r33, %r32, 1;
	st.u32 	[%rd1+16], %r33;
	bra.uni 	$L__BB2_7;

$L__BB2_6:
	ld.u32 	%r34, [%rd3];
	add.s32 	%r35, %r34, %r6;
	ld.const.u64 	%rd42, [params+56];
	cvta.to.global.u64 	%rd43, %rd42;
	mul.wide.u32 	%rd44, %r7, 4;
	add.s64 	%rd45, %rd43, %rd44;
	st.global.u32 	[%rd45], %r35;
	ld.u32 	%r36, [%rd3+4];
	ld.const.u64 	%rd46, [params+64];
	cvta.to.global.u64 	%rd47, %rd46;
	add.s64 	%rd48, %rd47, %rd44;
	st.global.u32 	[%rd48], %r36;
	ld.const.u64 	%rd49, [params+72];
	cvta.to.global.u64 	%rd50, %rd49;
	add.s64 	%rd51, %rd50, %rd44;
	st.global.f32 	[%rd51], %f3;
	ld.const.u64 	%rd52, [params+80];
	cvta.to.global.u64 	%rd53, %rd52;
	add.s64 	%rd54, %rd53, %rd44;
	st.global.f32 	[%rd54], %f4;

$L__BB2_7:
	ret;

}

